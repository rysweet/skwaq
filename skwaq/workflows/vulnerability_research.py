"""Vulnerability research workflow for the Skwaq vulnerability assessment copilot."""

from typing import Dict, List, Any, Optional, AsyncGenerator, Set
import asyncio
import json
from datetime import datetime
from skwaq.agents.vulnerability_agents import SkwaqAgent, VulnerabilityResearchAgent
from .base import Workflow
from ..db.neo4j_connector import get_connector
from ..utils.logging import get_logger

logger = get_logger(__name__)
# Default security focus areas for vulnerability research
DEFAULT_FOCUS_AREAS = [
    "Injection",
    "Authentication",
    "Authorization",
    "Sensitive Data Exposure",
    "Security Misconfiguration",
    "Input Validation",
    "Error Handling",
    "Cryptographic Issues",
]


class VulnerabilityResearchWorkflow(Workflow):
    """Workflow for conducting vulnerability research on a codebase."""

    def __init__(self, repository_id: str, focus_areas: Optional[List[str]] = None):
        """Initialize the vulnerability research workflow.
        Args:
            repository_id: The ID of the repository to analyze
            focus_areas: Optional list of security focus areas to analyze
        """
        super().__init__()
        self.repository_id = repository_id
        self.focus_areas = focus_areas or DEFAULT_FOCUS_AREAS
        self._paused = False
        self._current_phase = 0
        self._current_focus_area_index = 0
        self._findings = []

    def pause(self) -> None:
        """Pause the workflow iteration."""
        self._paused = True
        logger.info(
            f"Workflow paused at phase {self._current_phase}, focus area {self._current_focus_area_index}"
        )

    def resume(self) -> None:
        """Resume the workflow iteration."""
        self._paused = False
        logger.info(
            f"Workflow resumed from phase {self._current_phase}, focus area {self._current_focus_area_index}"
        )

    def should_continue(self) -> bool:
        """Check if the workflow should continue iterating.

        Returns:
            bool: True if the workflow should continue, False if it should stop
        """
        if self._paused:
            return False

        if self._current_phase >= 3:  # All phases complete
            return False

        if self._current_phase == 1 and self._current_focus_area_index >= len(self.focus_areas):
            return False

        return True

    async def run(self) -> AsyncGenerator[Dict[str, Any], None]:
        """Run the vulnerability research workflow.
        Yields:
            Dict[str, Any]: Progress updates and findings
        """
        self._current_phase = 0

        # Phase 1: Initial repository assessment
        yield {
            "phase": 1,
            "status": "starting",
            "message": "Beginning initial repository assessment",
        }
        repo_info = await self._get_repository_info()
        yield {
            "phase": 1,
            "status": "complete",
            "message": "Initial assessment complete",
            "data": repo_info,
        }

        if not self.should_continue():
            return
        # Phase 2: Focus area analysis
        self._current_phase = 1
        self._current_focus_area_index = 0

        while self._current_focus_area_index < len(self.focus_areas) and self.should_continue():
            focus_area = self.focus_areas[self._current_focus_area_index]
            yield {
                "phase": 2,
                "status": "in_progress",
                "message": f"Analyzing focus area: {focus_area}",
                "focus_area": focus_area,
                "progress": self._current_focus_area_index / len(self.focus_areas),
            }

            findings = await self._analyze_focus_area(focus_area)
            self._findings.extend(findings)

            yield {
                "phase": 2,
                "status": "focus_area_complete",
                "message": f"Completed analysis of {focus_area}",
                "findings": findings,
            }

            self._current_focus_area_index += 1
        if not self.should_continue():
            return
        # Phase 3: Consolidation and reporting
        self._current_phase = 2
        yield {
            "phase": 3,
            "status": "starting",
            "message": "Consolidating findings and generating report",
        }

        report = await self._generate_final_report()
        yield {
            "phase": 3,
            "status": "complete",
            "message": "Vulnerability research complete",
            "report": report,
            "findings": self._findings,
        }

    async def _get_repository_info(self) -> Dict[str, Any]:
        """Get basic information about the repository.

        Retrieves metadata about the repository from the database and performs
        an initial assessment of the codebase.

        Returns:
            Dictionary containing repository information
        """
        connector = get_connector()
        if not connector.connect():
            logger.error(f"Failed to connect to database for repository {self.repository_id}")
            return {"error": "Database connection failed"}

        # Fetch repository information from the database
        query = """
        MATCH (r:Repository {id: $repo_id})
        OPTIONAL MATCH (r)-[:CONTAINS]->(f:File)
        OPTIONAL MATCH (f)-[:USES_LANGUAGE]->(l:Language)
        WITH r, count(f) as file_count, collect(distinct l.name) as languages
        RETURN r.name as name, r.url as url, r.description as description,
               file_count, languages, r.last_updated as last_updated
        """

        result = connector.run_query(query, {"repo_id": self.repository_id})
        if not result:
            logger.warning(f"No repository found with ID {self.repository_id}")
            return {"error": f"Repository {self.repository_id} not found"}

        repo_data = result[0]

        # Get file types distribution
        file_types_query = """
        MATCH (r:Repository {id: $repo_id})-[:CONTAINS]->(f:File)
        WITH f.extension as extension, count(*) as count
        WHERE extension IS NOT NULL
        RETURN extension, count
        ORDER BY count DESC
        LIMIT 10
        """

        file_types = connector.run_query(file_types_query, {"repo_id": self.repository_id})

        # Calculate complexity metrics
        complexity_query = """
        MATCH (r:Repository {id: $repo_id})-[:CONTAINS]->(f:File)
        WHERE f.complexity IS NOT NULL
        RETURN avg(f.complexity) as avg_complexity,
               max(f.complexity) as max_complexity,
               min(f.complexity) as min_complexity
        """

        complexity = connector.run_query(complexity_query, {"repo_id": self.repository_id})

        # Assemble the repository information
        repo_info = {
            "name": repo_data.get("name", "Unknown"),
            "url": repo_data.get("url"),
            "description": repo_data.get("description"),
            "file_count": repo_data.get("file_count", 0),
            "languages": repo_data.get("languages", []),
            "last_updated": repo_data.get("last_updated"),
            "file_types": {item["extension"]: item["count"] for item in file_types},
            "complexity": complexity[0] if complexity else {"avg_complexity": None},
            "assessment_date": datetime.now().isoformat(),
        }

        logger.info(f"Retrieved repository info for {repo_info['name']} ({self.repository_id})")
        return repo_info

    async def _analyze_focus_area(self, focus_area: str) -> List[Dict[str, Any]]:
        """Analyze a specific security focus area.

        Uses the vulnerability research agent to analyze code related to
        a specific security focus area.

        Args:
            focus_area: The security focus area to analyze

        Returns:
            List of findings related to the focus area
        """
        logger.info(f"Starting analysis of focus area: {focus_area}")
        findings = []

        # Initialize the vulnerability research agent
        vuln_research_agent = VulnerabilityResearchAgent()

        # Get relevant files for this focus area
        connector = get_connector()
        files = await self._get_files_for_focus_area(focus_area)

        # Process each file
        for file in files:
            file_id = file.get("id")
            file_path = file.get("path")
            language = file.get("language", "Unknown")
            content = file.get("content", "")

            if not content:
                logger.warning(f"Empty content for file {file_path}, skipping")
                continue

            logger.info(f"Analyzing file {file_path} for {focus_area} vulnerabilities")

            # Generate context for the analysis
            context = {
                "focus_area": focus_area,
                "file_path": file_path,
                "language": language,
                "repository_id": self.repository_id,
            }

            # Research potential vulnerabilities in this file related to the focus area
            file_findings = await vuln_research_agent.research_vulnerability(
                vulnerability_type=focus_area, evidence=content, context=context
            )

            # If vulnerabilities were found, add them to the findings list
            if file_findings.get("confirmed", False):
                finding = {
                    "file_id": file_id,
                    "file_path": file_path,
                    "focus_area": focus_area,
                    "vulnerability_type": file_findings.get("vulnerability_type"),
                    "description": file_findings.get("description"),
                    "severity": file_findings.get("severity", "Unknown"),
                    "cwe_id": file_findings.get("cwe_id"),
                    "remediation": file_findings.get("remediation", ""),
                    "timestamp": datetime.now().isoformat(),
                }

                findings.append(finding)

                # Store the finding in the database
                await self._store_finding(finding)

        logger.info(
            f"Completed focus area analysis: {focus_area}, found {len(findings)} vulnerabilities"
        )
        return findings

    async def _get_files_for_focus_area(self, focus_area: str) -> List[Dict[str, Any]]:
        """Get files that are relevant for a specific security focus area.

        Args:
            focus_area: The security focus area

        Returns:
            List of relevant files with their content
        """
        connector = get_connector()

        # Map focus areas to relevant file patterns and keywords
        focus_area_mapping = {
            "Injection": {
                "keywords": ["sql", "query", "execute", "injection", "sanitize", "escape"],
                "extensions": [".sql", ".py", ".js", ".php", ".java", ".cs"],
            },
            "Authentication": {
                "keywords": ["auth", "login", "password", "credential", "session", "token"],
                "extensions": [".py", ".js", ".php", ".java", ".cs", ".go", ".rb"],
            },
            "Authorization": {
                "keywords": ["role", "permission", "access", "authz", "rbac", "acl"],
                "extensions": [".py", ".js", ".php", ".java", ".cs", ".go", ".rb"],
            },
            "Sensitive Data Exposure": {
                "keywords": ["encrypt", "decrypt", "secret", "key", "password", "token", "pii"],
                "extensions": [".py", ".js", ".php", ".java", ".cs", ".go", ".rb", ".conf"],
            },
            "Security Misconfiguration": {
                "keywords": ["config", "setting", "env", "environment", "setup", "init"],
                "extensions": [".json", ".yml", ".yaml", ".xml", ".conf", ".cfg", ".ini"],
            },
            "Input Validation": {
                "keywords": ["input", "validate", "sanitize", "parse", "escape", "filter"],
                "extensions": [".py", ".js", ".php", ".java", ".cs", ".go", ".rb"],
            },
            "Error Handling": {
                "keywords": ["error", "exception", "catch", "try", "finally", "handle"],
                "extensions": [".py", ".js", ".php", ".java", ".cs", ".go", ".rb"],
            },
            "Cryptographic Issues": {
                "keywords": ["crypt", "hash", "salt", "key", "encrypt", "decrypt", "sign"],
                "extensions": [".py", ".js", ".php", ".java", ".cs", ".go", ".rb"],
            },
        }

        # Get the mapping for the current focus area
        mapping = focus_area_mapping.get(
            focus_area, {"keywords": [], "extensions": [".py", ".js", ".java", ".cs"]}
        )

        # Build a Cypher query to find relevant files
        query = """
        MATCH (r:Repository {id: $repo_id})-[:CONTAINS]->(f:File)
        WHERE 
            (ANY(ext IN $extensions WHERE f.path ENDS WITH ext))
            OR
            (ANY(kw IN $keywords WHERE f.content CONTAINS kw))
        WITH f, f.path as path
        ORDER BY f.complexity DESC
        LIMIT 10
        MATCH (f)-[:USES_LANGUAGE]->(l:Language)
        RETURN id(f) as id, f.path as path, l.name as language, f.content as content
        """

        params = {
            "repo_id": self.repository_id,
            "extensions": mapping["extensions"],
            "keywords": mapping["keywords"],
        }

        result = connector.run_query(query, params)

        # If no files found with specific criteria, get the top 5 most complex files
        if not result:
            logger.warning(
                f"No specific files found for {focus_area}, falling back to most complex files"
            )
            fallback_query = """
            MATCH (r:Repository {id: $repo_id})-[:CONTAINS]->(f:File)
            WITH f ORDER BY f.complexity DESC
            LIMIT 5
            MATCH (f)-[:USES_LANGUAGE]->(l:Language)
            RETURN id(f) as id, f.path as path, l.name as language, f.content as content
            """
            result = connector.run_query(fallback_query, {"repo_id": self.repository_id})

        logger.info(f"Retrieved {len(result)} files for focus area: {focus_area}")
        return result

    async def _store_finding(self, finding: Dict[str, Any]) -> None:
        """Store a vulnerability finding in the database.

        Args:
            finding: The vulnerability finding to store
        """
        connector = get_connector()

        # Create a Finding node
        finding_props = {
            "file_path": finding["file_path"],
            "vulnerability_type": finding["vulnerability_type"],
            "description": finding["description"],
            "severity": finding["severity"],
            "cwe_id": finding.get("cwe_id"),
            "remediation": finding.get("remediation", ""),
            "timestamp": finding["timestamp"],
        }

        finding_id = connector.create_node(["Finding", "Vulnerability"], finding_props)

        if finding_id:
            # Connect the finding to the file
            file_id = finding["file_id"]
            connector.create_relationship(
                finding_id, file_id, "FOUND_IN", {"focus_area": finding["focus_area"]}
            )

            # Connect the finding to the repository
            repo_query = "MATCH (r:Repository {id: $repo_id}) RETURN id(r) as id"
            repo_result = connector.run_query(repo_query, {"repo_id": self.repository_id})

            if repo_result:
                repo_id = repo_result[0]["id"]
                connector.create_relationship(
                    finding_id, repo_id, "BELONGS_TO", {"timestamp": finding["timestamp"]}
                )

        logger.debug(f"Stored finding in database with ID {finding_id}")

    async def _generate_final_report(self) -> Dict[str, Any]:
        """Generate the final vulnerability research report.

        Consolidates all findings and generates a comprehensive
        vulnerability assessment report.

        Returns:
            Dictionary containing the final report
        """
        logger.info("Generating final vulnerability report")

        # Get repository info
        repo_info = await self._get_repository_info()

        # Calculate statistics
        severity_counts = {"Critical": 0, "High": 0, "Medium": 0, "Low": 0, "Unknown": 0}
        focus_area_counts = {area: 0 for area in self.focus_areas}

        # Count findings by severity and focus area
        for finding in self._findings:
            severity = finding.get("severity", "Unknown")
            focus_area = finding.get("focus_area")

            if severity in severity_counts:
                severity_counts[severity] += 1

            if focus_area in focus_area_counts:
                focus_area_counts[focus_area] += 1

        # Get the most severe findings (top 5)
        severity_order = ["Critical", "High", "Medium", "Low", "Unknown"]
        most_severe = sorted(
            self._findings, key=lambda x: severity_order.index(x.get("severity", "Unknown"))
        )[:5]

        # Calculate the overall risk score (weighted average of severity counts)
        severity_weights = {"Critical": 4, "High": 3, "Medium": 2, "Low": 1, "Unknown": 1}
        total_findings = sum(severity_counts.values())

        risk_score = 0
        if total_findings > 0:
            weighted_sum = sum(severity_counts[s] * severity_weights[s] for s in severity_counts)
            risk_score = round((weighted_sum / total_findings) * 25, 1)  # Scale to 0-100

        # Generate recommendations based on findings
        recommendations = await self._generate_recommendations()

        # Compile the final report
        report = {
            "title": f"Security Assessment Report for {repo_info.get('name', 'Repository')}",
            "date": datetime.now().isoformat(),
            "repository": {
                "id": self.repository_id,
                "name": repo_info.get("name"),
                "url": repo_info.get("url"),
                "description": repo_info.get("description"),
            },
            "summary": {
                "total_vulnerabilities": total_findings,
                "risk_score": risk_score,
                "severity_distribution": severity_counts,
                "focus_area_distribution": focus_area_counts,
            },
            "key_findings": [
                {
                    "vulnerability_type": finding.get("vulnerability_type"),
                    "severity": finding.get("severity"),
                    "file_path": finding.get("file_path"),
                    "description": finding.get("description"),
                }
                for finding in most_severe
            ],
            "recommendations": recommendations,
            "detailed_findings": self._findings,
        }

        # Store the report in the database
        await self._store_report(report)

        logger.info(f"Completed vulnerability report with {total_findings} findings")
        return report

    async def _generate_recommendations(self) -> List[Dict[str, str]]:
        """Generate security recommendations based on findings.

        Returns:
            List of recommendation dictionaries
        """
        # Group findings by vulnerability type
        vuln_types = {}
        for finding in self._findings:
            vuln_type = finding.get("vulnerability_type")
            if vuln_type not in vuln_types:
                vuln_types[vuln_type] = []
            vuln_types[vuln_type].append(finding)

        recommendations = []

        # Generate recommendations for each vulnerability type
        for vuln_type, findings in vuln_types.items():
            # Get the most common remediation advice
            remediations = [f.get("remediation", "") for f in findings if f.get("remediation")]

            if remediations:
                # Use the most detailed remediation as the basis
                recommendation = max(remediations, key=len)
            else:
                # Fallback generic recommendation
                recommendation = (
                    f"Address {vuln_type} vulnerabilities by implementing proper security controls."
                )

            recommendations.append(
                {
                    "category": vuln_type,
                    "recommendation": recommendation,
                    "priority": (
                        "High"
                        if any(f.get("severity") in ["Critical", "High"] for f in findings)
                        else "Medium"
                    ),
                }
            )

        return recommendations

    async def _store_report(self, report: Dict[str, Any]) -> None:
        """Store the final report in the database.

        Args:
            report: The report to store
        """
        connector = get_connector()

        # Create a Report node
        report_props = {
            "title": report["title"],
            "date": report["date"],
            "total_vulnerabilities": report["summary"]["total_vulnerabilities"],
            "risk_score": report["summary"]["risk_score"],
            "json_data": json.dumps(report),
        }

        report_id = connector.create_node("Report", report_props)

        if report_id:
            # Connect the report to the repository
            repo_query = "MATCH (r:Repository {id: $repo_id}) RETURN id(r) as id"
            repo_result = connector.run_query(repo_query, {"repo_id": self.repository_id})

            if repo_result:
                repo_id = repo_result[0]["id"]
                connector.create_relationship(
                    report_id, repo_id, "ASSESSES", {"timestamp": report["date"]}
                )

        logger.debug(f"Stored final report in database with ID {report_id}")
